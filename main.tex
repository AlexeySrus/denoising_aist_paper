% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
\usepackage{mathtools}

\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Unsupervised training denoising networks}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Alexey Kovalenko\inst{1}\orcidID{0000-0003-4185-3491} \and
Yana Demyanenko\inst{1}\orcidID{0000-0002-0567-7614}}
%
\authorrunning{A. Kovalenko \and Y. Demyanenko}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Southern Federal University
\email{gor@sfedu.ru}\\
\url{https://www.sfedu.ru/}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
This work explore approach for image denoising of received by CMOS sensor. Proposed pipeline solves the problem of unsupervised training neural network architectures for image denoising which uses datasets without clean data. This approach bases on theoretical background about image restoration proposed by Nvidia researchers. We implemented custom denoising neural network architectures using specifics of noise distribution. Networks are trained on custom images collection.

\keywords{Image denoising  \and unsupervised learning \and neural networks \and learning image denoising.}
\end{abstract}
%
%
%
\section{Introduction}
Noise reduction is common problem in computer vision. Any image captured by CMOS sensor contains noise. This noise appears in useful signal due to errors in reception of optical radiation by sensor. Clear image signal will be denoted by $I$, and noise component denoted by $\alpha$. Assuming that the process of noise occurrence is an absolutely random process from the distribution of $\mathit{P}$. Then the matrix of the final image can be denoted by formula~(\ref{eq:matrix_def}).

\begin{equation}\label{eq:matrix_def}
\tilde{I}\ =\ I\ +\ \alpha,\ \alpha \sim \mathit{P}
\end{equation}

Since the error in receiving optical signal depends on physical device of the CMOS sensor, that for each model of the sensor there will be a unique distribution of $\mathit{P}$, which generates the noise component of the signal.

The goal of this work is approximation of the function $\phi: \mathit{R}^n \longrightarrow  \mathit{R}^n$ by neural network, which has the following property:

\begin{equation}\label{eq:main_property}
\forall \tilde{I} \Longrightarrow \phi(\tilde{I}) = I 
\end{equation}
For build of approximation of the mapping $\phi$, the neural network $f$ will be trained to solve the following optimization problem:
\begin{eqnarray}\label{eq:main_min_task}
\min_{\mathnormal{w}} \Arrowvert f(\tilde{I}, \mathnormal{w}) - I \Arrowvert_{L_2}\mathit{ ,}
\end{eqnarray}
where $\mathnormal{w}$ - neural network weights $f$, $L_2$ - Euclidean norm.


\section{Related works}
Significant contribution to the denoising problem by neural networks is made by the work of Nvidia researchers. This work is titled Noise2 Noise: Learning Image Restoration without Clean Data~\cite{noise2noise_paper}. The main idea of this work is using representation of noise as a composition of a clear signal and unique noise received at different points in time to train a neural network to restore a clean image signal. A noisy image with the noise component $\alpha_1$ is forward to neural network and the network is required to predict the same image, but with the noise component $\alpha_2$. Assuming that the noise was obtained randomly, the neural network is not able to predict it, and therefore, during training, the neural network seeks to reconstruct the image with some losses. The disadvantage of this approach is the use of only a pair of images of one scene during training, which can result in large losses of the useful signal during network operation.

There is also a lot of researches touch upon problem of training noise reduction networks on datasets containing images without a noise component. An example of this approach is the work of engineers from Google which titled Unprocessing Images for Learned Raw Denoising~\cite{google_paper}. In this work, the authors will train the network using the standard error function $L_1$. And tested this network on a Darmstadt Noise Dataset dataset~\cite{raw_dataset}.

Darmstadt Noise Dataset datasets contains pairs of images. Each pair consists of an image taken with correctly selected camera parameters for shooting and an image having noises arising from incorrect parameters. Networks trained on such data sets do not solve the problem of suppressing noise arising from the CMOS sensor of a camera even in the most correctly selected shooting parameters.

Thus, for training a network focused on denoising from a specific CMOS sensor, it becomes necessary to collect data and develop a method for training a network on them.

Together with Noise2Noise work~\cite{noise2noise_paper}, there are state-of-the-art approaches such as Noise2Void~\cite{noise2void_paper}, Noise2Self~\cite{noise2self_paper} and Deep Image Prior~\cite{deep_image_prior_paper}, contributing to the field of unsupervised learning of denoising neural networks.

% Помимо N2N существуют различные современные методы, такие как N2V, N2S, Deep Image prior, вносящие вклад в область неконтрролируемого одбучения шумоподавляющих нейнронных сетей.

\section{Dataset}
\label{sec:dataset}

\subsection{Collecting dataset}

Images for training dataset were obtained using a certain device, \textit{Apple iPhone X}, which has a camera consisting of two sensors, with the characteristics given in the following source~\cite{camera_chars}.

From this device a series of RAW images of seven scenes with different lighting and color component ware obtained. A scene made by shooting an static picture of the real world, getting the matrix~(\ref{eq:matrix_def}). To do this, the device was fixed on a tripod in a stationary state and the shooting process was started from a wireless device, thereby obtaining a set of images $\{\tilde{I}^q_k\}_{k=1}^{N}$, where $q$ is the sequence number of the scene being shot. For each series ISO, focus and color temperature values were fixed when shooting.

Each scene contains about $14$ photos. Total number of frames from all sets is $ 95 $ images.

The maximum number of images in one series is limited to $20$ frames because CMOS sensor heats with long time the shooting process continues and additional signal distortions appear due to thermal effects. Due to this effect of which the pixel-by-pixel correspondence of frames in the series to each other is lost.

The result is a dataset consisting of $125$ images taken on one sensor.

Also, to compare the results, 6 series were made, shot by next web camera in the resolution of $1920\times1080$. Short videos were shot and divided into frames. Total number of frames in these series was $811$.

\subsection{Analysing dataset}
During the shooting process, slight distortion of the frame may occur when the photosensor is heated. Or imperceptible displacements of the device during shooting, as well as a change in external conditions, such as lighting or movement of objects in the frame, are also possible. For an collected set of images, a shift value of more than one pixel between frames of the same series is already critical.

To analyze the quality of the obtained series of images, the distributions of $e^q$~(\ref{eq:series_distribution}) deviations of each image from the average over all images from the series $\hat{I}^q$ by the Euclidean metric.

\begin{eqnarray}\label{eq:mean_image}
\hat{I}^q_{i,j}\ =\ \frac{\sum_{k}\tilde{I}^q_{k\ i,j}}{N}\textit{, where }N\textit{ is count of frames in series }q
\end{eqnarray}

\begin{eqnarray}\label{eq:series_distribution}
e^q_k\ =\ \Arrowvert \hat{I}^q - \tilde{I}^q_k \Arrowvert_{L_2}
\end{eqnarray}
Additionally, the series is normalized by metric $L_1$:
$$e^q_k\ =\ \frac{e^q_k}{\sum_{i}(e^q_i)}$$

Then, using the values of the sample $e^q$~(\ref{eq:series_distribution}), we plot the density curves of the normal distribution $\mathcal{N}(\mu, \sigma)$ with the parameters:
\begin{eqnarray}\label{eq:mean_and_std}
\mu^q = \mu(e^q),\ \sigma^q = \sigma(e^q)
\end{eqnarray}

Thus, the mathematical expectation of $\mu^q$~(\ref {eq:mean_and_std}) shows how near the average image of $\hat{I}^q$~(\ref{eq:mean_image}  to the image theoretically obtained from a pure signal $I^q$: 
\begin{eqnarray}\label{eq:mean_image_approximation}
\hat{I}^q \xrightarrow[\mu^q \rightarrow 0]{} I^q
\end{eqnarray}

And also, the near to $0$ the value of the standard deviation of the sample $\sigma^q$~(\ref{eq:mean_and_std}), the more images from the series there is a signal of static scene, fixed at time $ t = t_0 $, that is, how much the scene is unchanged between frames.

For example, the deviation parameter $\sigma$~(\ref{eq:mean_and_std} may be quite large with different illumination of the same scene between frames (see Fig.~\ref{fig:hists_comparision}).

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/imgs_8_series_stack_image}
	\caption{Series of images with color histograms, the parameter $\sigma$ of this series is $0.00608$}
	\label{fig:hists_comparision}
\end{figure}

For demonstrate the various values of the deviation parameter, a graph is constructed (see Fig.~\ref{fig:distribuion_real_noise_good_condition}).


\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/good_condition_series_real_noise_iphone_deviation_comparison}
	\caption{Normal distribution density plots for series shot under natural light conditions}
	\label{fig:distribuion_real_noise_good_condition}
\end{figure}


When choosing data for training neural networks, the condition is set that the parameter $\sigma$~(\ref{eq:mean_and_std}) should not exceed the value of $0.007$.


\section{Method}
\label{sec:method}

In this work we produce a novel method for training denoising neural network architectures. This approach combine traditional supervised method for training autoencoder neural network architectures and approach produced by authors of Noise2Noise work~\cite{noise2noise_paper}.

When we have image series of one scene obtained in different time~(see Section~\ref{sec:dataset}), we can average this image series and made approximation of expected clear image. Obtained mean image can be used for train the denoising neural network as the expected output signal $y^\prime$ in solving of loss $E$ minimization problem~(\ref{eq:loss_optim}). An input signal $x$ can be taken random image from series under consideration. But in this case value $y^\prime$ consists noise component from input signal $x$. If input image has been excluded from series before averaging step, then we made approximation of clear image without noise component of input signal and this setting is consistent with theory of Noise2Noise work~\cite{noise2noise_paper}. This ground truth signal $y^\prime$ are constructed using the formula~(\ref{eq:dataset}). Thereby, when we train denoising network to predict signal $y^\prime$, it train to extract additional features from input signal by Noise2Noise approach logic for achieving more denoising quality.
Scheme of this approach also is shown~(see Fig.~\ref{fig:denoising_training}).

\begin{equation}\label{eq:dataset}
X_i = \tilde{I_i},\ y = \frac{\sum_{k=1, k \ne i}^{N}\tilde{I_k}}{N - 1}
\end{equation}

\begin{figure}
	\centering
	\includegraphics[scale=0.14]{img/denoising_training}
	\caption{Scheme of training pipeline}
	\label{fig:denoising_training}
\end{figure}

\begin{eqnarray}\label{eq:loss_optim}
\min_{\mathnormal{w}} E(f(x), y^\prime)
\end{eqnarray}

\section{Architecture}

\subsection{Base architecture block}

To build architectures in this work for test proposed approach, the blocks from the ResNet~\cite{resnet_paper} architecture were taken and modified. From ResNet blocks batch normalization layers has been excluded. The scheme of these blocks is shown(see Fig.~\ref{fig:detail_adjuster_resnet_block}).

\begin{figure}
	\centering
	\includegraphics[scale=0.07]{img/resnet_adjusted}
	\caption{Detailed scheme of modified ResNet block} 
	\label{fig:detail_adjuster_resnet_block}
\end{figure}


\subsection{Architecture with frequency components splitting}
\label{sec:architecture}

The noise in question~(\ref{eq:matrix_def}) belongs to the high frequency component of the image signal. An example of decomposition of an image signal into high and low frequencies using the Butterworth filter is shown(see Fig.~\ref {fig:fft_comparison}).

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/fft_comparison}
	\caption{From left to right: original part of the image, 2D Fourier spectrum for the grayscale image, rendering of the Butterworth filter, low-frequency component of the image, high-frequency component of the image}
	\label{fig:fft_comparison}
\end{figure}

Taking into account such a distribution of the noise component, an architecture was developed with the separation of the signal into high-frequency and low-frequency signals and their further independent processing by the convolutional layers of the network. This scheme is shown(see Fig.~\ref{fig:architecture_fft_decomposition}).

\begin{figure}
	\centering
	\includegraphics[scale=0.045]{img/architecture_fft_decomposition}
	\caption{Detailed architecture diagram of denoising network with frequency decomposition of input image}
	\label{fig:architecture_fft_decomposition}
\end{figure}

Implemented architecture (see Fig.~\ref{fig:architecture_fft_decomposition}) consists of a layer of frequency signal decomposition and sequential processing of parts of the input signal using convolutional blocks. Then the signals from blocks with are concatenated by channels and processed by a 3D convolutional layer to extract high-level features with interchannel dependence.

This architecture has $511390$ of trainable parameters and the weight of this model is $2$ megabytes when using single precision FP32 numbers to store the parameters.

\section{Training}

In the experiment we train architecture with frequency components splitting~(see Section~\ref{sec:architecture}) by proposal approach~(see Section~\ref{sec:method}) on our dataset~(see Section~\ref{sec:dataset}).

To use all frames from a series of images, one frame from a series was use to the network input, and a series averaging without an input frame was used as the expected output signal~(see Section~\ref{sec:method}). Based on the sample \\$\{\tilde{I} _k\} _ {k=1}^{N}$, the input $X$ and the expected at the output of the network $y$ are constructed using the formula~(~\ref{eq:dataset}).

Denoising model was trained on random cropped images and using the following augmentation: rotations by 90, 180, 270 degrees and flips.

For denoising models training was implemented pipeline based on PyTorch framework. As optimizer for was models training used radam optimizer~\cite{radam_paper}.

\section{Inference}
On inference input image unfolds on grid of crop. Network forwards on each crop with test-time data augmentation with transforms from training~\cite{test_ts_augmentations_paper}. Result image computed by formula~(\ref{eq:times_series_augmentation}), where $T_{i}$ - augmentation transform, $T_{i}^{-1}$ - inverse transform.

\begin{eqnarray}\label{eq:times_series_augmentation}
I_{result}\ =\ \frac{\sum_{n=1}^{8} T_{i}^{-1}(T_{i}(f(x)))}{8}
\end{eqnarray}


\section{Results}
To test the quality of noise reduction, the PSNR (Peak Signal-to-Noise Ratio) metric is usually used. But this metric is incorrect for a datasets where there is no clean samples. PSNR between output of the architecture which not completely reduced noise and average series value can be more then PSNR between output of the architecture which completely reduce noise component and the average series. This is due to the fact that a noise component remains in the average value of the series. In this case PSNR measure incorrect, but we have not another way to comparison our solution with state-of-the-art denoising approaches.

We compare our method with state-of-the-art approaches for training unsupervised image denoising neural networks . Before comparison neural network of each work we train by authors pipeline on our dataset. In addition for comparison taken an unsupervised image denoising algorithm from the OpenCV library: Non-local means denoising~\cite{nlmd_paper}. Table~\ref{tab:comparison} gives comparison results. Furthermore visual comparison of inference all approaches is shown~(see Fig.~\ref{fig:approaches_comparison}). Additional shown comparison with Non-local means denoising~\cite{nlmd_paper}~(see Fig.~\ref{fig:real_noise_advanced}).

\begin{table}
\centering
\caption{Comparison proposal approach with related works}\label{tab:comparison}	
\begin{tabular}{|l|l|}	
	\hline	
	Approach &  PSNR \\	
	\hline	
	Noise2Noise &  {34.6} \\	
	Noise2Void &  {30.53} \\	
	Noise2Self & {33.7} \\
	Non-local Means Denoising\hspace{1cm} & {36.04} \\
	Deep Image Prior & {36.34} \\
	Our & {\bfseries 37.1} \\	
	\hline	
\end{tabular}	
\end{table}


\begin{figure}
	\centering
	\includegraphics[scale=0.1]{img/approaches_comparison}
	\caption{From left to right on first line: image obtained by averaging all frames in series, original image, result of Noise2Noise, result of Noise2Self, from left to right of second line: result of Noise2Void, result of the non-local means denoising, result of Deep Image Prior, result of the architecture with frequency decomposition of input signal}
	\label{fig:approaches_comparison}
\end{figure}

These models work only with frames received from the CMOS sensor from which the dataset was obtained for their training. An example of work on frames from another sensor is shown (see Fig.~\ref{fig:real_noise_webacam_advanced}). Poor prediction quality is noticeably.


\begin{figure}
	\centering
	\includegraphics[scale=0.2]{img/real_noise_advanced}
	\caption{From left to right: original image, image obtained by averaging all frames in series, result of the architecture with frequency decomposition of input signal, result of the non-local means denoising}
	\label{fig:real_noise_advanced}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[scale=0.25]{img/real_noise_webacam_advanced}
	\caption{From left to right: original image, image obtained by averaging all frames in series, result of the architecture with frequency decomposition of input signal,, result of the non-local means denoising}
	\label{fig:real_noise_webacam_advanced}
\end{figure}

\section{Summary}
As a result pipeline was implemented for training the noise reduction model. It does not depend on datasets with clean sample images.
A neural network architecture was implemented and tested to effectively solve the noise reduction problem without clean data.

According to the visual results, the proposed model solves the optimization problem~(\ref{eq:main_min_task}) quite efficiently. All experiments were performed on the dataset collected for this work.

The source code is available at the following link:

\textbf{https://github.com/AlexeySrus/image\_denoising}


% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\begin{thebibliography}{8}
\bibitem{noise2noise_paper}
Lehtinen, J., Munkberg, J., Laine, S., Karras, T., Aittala, M., Aila, T.: Noise2Noise: Learning Image Restoration without Clean Data. CoRR abs/1803.04189, (2018). http://arxiv.org/abs/1803.04189
	
\bibitem{google_paper}
Brooks, T., Mildenhall, B., Xue, T., Chen, J., Sharlet, D., Barron, J.: Unprocessing Images for Learned Raw Denoising. CoRR abs/1811.11127, (2018). http://arxiv.org/abs/1811.11127

\bibitem{raw_dataset}
Plotz, T., Roth, S.: Benchmarking Denoising Algorithms with Real Photographs. CoRR abs/1707.0131, (2017). http://arxiv.org/abs/1707.01313

\bibitem{noise2void_paper}
Krull, A., Buchholz, T.-O., Jug, F.: Noise2Void - Learning Denoising from Single Noisy Images. CoRR abs/1811.10980, (2018). http://arxiv.org/abs/1811.10980

\bibitem{noise2self_paper}
Batson, J., Royer, L.: Noise2Self: Blind Denoising by Self-Supervision. CoRR abs/1901.11365, (2019). https://arxiv.org/abs/1901.11365

\bibitem{deep_image_prior_paper}
Ulyanov, D., Vedaldi, A., Lempitsky, V.: Deep Image Prior. CoRR abs/1711.10925, (2017). https://arxiv.org/abs/1711.10925

\bibitem{camera_chars}
GSMARENA, https://www.gsmarena.com/apple\_iphone\_x-8858.php.  Last accessed 20 Jun 2020

\bibitem{resnet_paper}
He, K., Zhang, X., Ren, S., Sun, J.: Deep Residual Learning for Image Recognition. CoRR abs/1512.03385, (2015). http://arxiv.org/abs/1512.03385

\bibitem{radam_paper}
Liyuan, L., Haoming, J., Pengcng, H., Weizhu, C., Xiaodong, L., Jianfeng, G., Jiawei, H.: On the Variance of the Adaptive Learning Rate and Beyond. CoRR abs/1908.03265, (2019). http://arxiv.org/abs/1908.03265

\bibitem{test_ts_augmentations_paper}
Ayhan, M., Berens, P.: Test-time Data Augmentation for Estimation of Heteroscedastic Aleatoric Uncertainty in Deep Neural Networks. MIDL 2018 Conference, (2018). https://openreview.net/forum?id=rJZz-knjz

\bibitem{nlmd_paper}
Buades, A., Coll, B., Morel, J.-M.: Median Filtering: A New Insight. Image Processing On Line, (2011). http://dx.doi.org/10.5201/ipol.2011.bcm\_nlm
\end{thebibliography}
\end{document}

