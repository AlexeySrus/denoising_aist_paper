% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
\usepackage[russian]{babel}%
\usepackage{mathtools}

\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Unsupervised training denoising networks}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Alexey Kovalenko\inst{1}\orcidID{0000-0003-4185-3491} \and
Yana Demyanenko\inst{1}\orcidID{1111-2222-3333-4444}}
%
\authorrunning{A. Kovalenko \and Y. Demyanenko}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Southern Federal University, 	Rostov-on-Don, Russia
\email{sfedu email}\\
\url{https://www.sfedu.ru}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
This work explore approach for image denoising of received by CMOS sensor. Proposed pipeline solves the problem of unsupervised training neural network architectures for image denoising which uses datasets without clean data. This approach bases on theoretical background about image restoration proposed by Nvidia researchers. We implemented custom denoising neural network architectures using specifics of noise distribution. Networks are trained on custom images collection.

\keywords{Image denoising  \and unsupervised learning \and neural networks \and learning image denoising.}
\end{abstract}
%
%
%
\section{Introduction}
Noise reduction is common problem in computer vision. Any image captured by CMOS sensor contains noise. This noise appears in useful signal due to errors in reception of optical radiation by sensor. Clear image signal will be denoted by $I$, and noise component denoted by $\alpha$. Assuming that the process of noise occurrence is an absolutely random process from the distribution of $\mathit{P}$. Then the matrix of the final image can be denoted by formula~(\ref{eq:matrix_def}).

\begin{equation}\label{eq:matrix_def}
\tilde{I}\ =\ I\ +\ \alpha,\ \alpha \sim \mathit{P}
\end{equation}

Since the error in receiving optical signal depends on physical device of the CMOS sensor, that for each model of the sensor there will be a unique distribution of $\mathit{P}$, which generates the noise component of the signal.

The goal of this work is approximation of the function $\phi: \mathit{R}^n \longrightarrow  \mathit{R}^n$ by neural netwok, which has the following property:

\begin{equation}\label{eq:main_property}
\forall \tilde{I} \Longrightarrow \phi(\tilde{I}) = I 
\end{equation}
For build of approximation of the mapping $\phi$, the neural network $f$ will be trained to solve the following optimization problem:
\begin{eqnarray}\label{eq:main_min_task}
\min_{\mathnormal{w}} \Arrowvert f(\tilde{I}, \mathnormal{w}) - I \Arrowvert_{L_2}\mathit{ ,}
\end{eqnarray}
where $\mathnormal{w}$ - neural network weights $f$, $L_2$ - Euclidean norm.


\section{Related works}
Significant contribution to the denoising problem by neural networks is made by the work of Nvidia researchers. This work is titled Noise2 Noise: Learning Image Restoration without Clean Data. The main idea of this work is using representation of noise as a composition of a clear signal and unique noise received at different points in time to train a neural network to restore a clean image signal. A noisy image with the noise component $\alpha_1$ is forward to neural network and the network is required to predict the same image, but with the noise component $\alpha_2$. Assuming that the noise was obtained randomly, the neural network is not able to predict it, and therefore, during training, the neural network seeks to reconstruct the image with some losses. The disadvantage of this approach is the use of only a pair of images of one scene during training, which can result in large losses of the useful signal during network operation.

There is also a lot of researches touch upon problem of training noise reduction networks on datasets containing images without a noise component. An example of this approach is the work of engineers from Google which titled Unprocessing Images for Learned Raw Denoising. In this work, the authors will train the network using the standard error function $L_1$. And tested this network on a Darmstadt Noise Dataset dataset.

Darmstadt Noise Dataset datasets contains pairs of images. Each pair consists of an image taken with correctly selected camera parameters for shooting and an image having noises arising from incorrect parameters. Networks trained on such data sets do not solve the problem of suppressing noise arising from the CMOS sensor of a camera even in the most correctly selected shooting parameters.

Thus, for training a network focused on denoising from a specific CMOS sensor, it becomes necessary to collect data and develop a method for training a network on them.

\section{Dataset}

\subsection{Collecting dataset}

Images for training dataset were obtained using a certain device, \textit{Apple iPhone X}, which has a camera consisting of two sensors, with the characteristics given in the following source (source).

From this device a series of RAW images of seven scenes with different lighting and color component ware obtained. A scene made by shooting an static picture of the real world, getting the matrix~(\ref{eq:matrix_def}). To do this, the device was fixed on a tripod in a stationary state and the shooting process was started from a wireless device, thereby obtaining a set of images $\{\tilde{I}^q_k\}_{k=1}^{N}$, where $q$ is the sequence number of the scene being shot. For each series ISO, focus and color temperature values were fixed when shooting.

Each scene contains about $14$ photos. Total number of frames from all sets is $ 95 $ images.

The maximum number of images in one series is limited to $20$ frames because CMOS sensor heats with long time the shooting process continues and additional signal distortions appear due to thermal effects. Due to this effect of which the pixel-by-pixel correspondence of frames in the series to each other is lost.

The result is a dataset consisting of $125$ images taken on one sensor.

Also, to compare the results, 6 series were made, shot by next web camera in the resolution of $1920\times1080$. Short videos were shot and divided into frames. Total number of frames in these series was $811$.

\subsection{Analysing dataset}
During the shooting process, slight distortion of the frame may occur when the photosensor is heated. Or imperceptible displacements of the device during shooting, as well as a change in external conditions, such as lighting or movement of objects in the frame, are also possible. For an collected set of images, a shift value of more than one pixel between frames of the same series is already critical.

To analyze the quality of the obtained series of images, the distributions of $e^q$~(\ref{eq:series_distribution}) deviations of each image from the average over all images from the series $\hat{I}^q$ by the Euclidean metric.

\begin{eqnarray}\label{eq:mean_image}
\hat{I}^q_{i,j}\ =\ \frac{\sum_{k}\tilde{I}^q_{k\ i,j}}{N}\textit{, where }N\textit{ is count of frames in series }q
\end{eqnarray}

\begin{eqnarray}\label{eq:series_distribution}
e^q_k\ =\ \Arrowvert \hat{I}^q - \tilde{I}^q_k \Arrowvert_{L_2}
\end{eqnarray}
Additionally, the series is normalized by metric $L_1$:
$$e^q_k\ =\ \frac{e^q_k}{\sum_{i}(e^q_i)}$$

Then, using the values of the sample $e^q$~(\ref{eq:series_distribution}), we plot the density curves of the normal distribution $\mathcal{N}(\mu, \sigma)$ with the parameters:
\begin{eqnarray}\label{eq:mean_and_std}
\mu^q = \mu(e^q),\ \sigma^q = \sigma(e^q)
\end{eqnarray}

Thus, the mathematical expectation of $\mu^q$~(\ref {eq:mean_and_std}) shows how near the average image of $\hat{I}^q$~(\ref{eq:mean_image}  to the image theoretically obtained from a pure signal $I^q$~(\ref{eq:collection}): 
\begin{eqnarray}\label{eq:mean_image_approximation}
\hat{I}^q \xrightarrow[\mu^q \rightarrow 0]{} I^q
\end{eqnarray}

And also, the near to $0$ the value of the standard deviation of the sample $\sigma^q$~(\ref{eq:mean_and_std}), the more images from the series there is a signal of static scene, fixed at time $ t = t_0 $, that is, how much the scene is unchanged between frames.

For example, the deviation parameter $\sigma$~(\ref{eq:mean_and_std} may be quite large with different illumination of the same scene between frames (see Fig.~\ref{fig:hists_comparision}).

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/imgs_8_series_stack_image}
	\caption{Series of images with color histograms, the parameter $\sigma$ of this series is $0.00608$}
	\label{fig:hists_comparision}
\end{figure}

For demonstrate the various values of the deviation parameter, a graph is constructed (see Fig.~\ref{fig:distribuion_real_noise_good_condition}).


\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/good_condition_series_real_noise_iphone_deviation_comparison}
	\caption{Normal distribution density plots for series shot under natural light conditions}
	\label{fig:distribuion_real_noise_good_condition}
\end{figure}


When choosing data for training neural networks, the condition is set that the parameter $\sigma$~(\ref{eq:mean_and_std}) should not exceed the value of $0.007$.


\section{Architectures}

\subsection{Base architecture block}

To build architectures in this work, the blocks from the ResNet architecture were taken and modified. The scheme of these blocks is shown(see Fig.~\ref{fig:detail_adjuster_resnet_block}).

\begin{figure}
	\centering
	\includegraphics[scale=0.07]{img/resnet_adjusted}
	\caption{Detailed scheme of modified ResNet block} 
	\label{fig:detail_adjuster_resnet_block}
\end{figure}

\subsection{Mobile architecture}

Based on the blocks (see Fig.~\ref{fig:detail_adjuster_resnet_block}), an architecture is constructed that has a small number of trained parameters and a high speed of operation (see Fig.~\ref{fig:simple_net_architecture}).

\begin{figure}
	\centering
	\includegraphics[scale=0.07]{img/simple_net_architecture}
	\caption{Scheme of mobile denoising architecture} 
	\label{fig:simple_net_architecture}
\end{figure}

\subsection{Architecture with frequency components splitting}

The noise in question~(\ref{eq:matrix_def}) belongs to the high frequency component of the image signal. An example of decomposition of an image signal into high and low frequencies using the Butterworth filter is shown(see Fig.~\ref {fig:fft_comparison}).

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{img/fft_comparison}
	\caption{From left to right: original part of the image, 2D Fourier spectrum for the grayscale image, rendering of the Butterworth filter, low-frequency component of the image, high-frequency component of the image}
	\label{fig:fft_comparison}
\end{figure}

Taking into account such a distribution of the noise component, an architecture was developed with the separation of the signal into high-frequency and low-frequency signals and their further independent processing by the convolutional layers of the network. This scheme is shown(see Fig.~\ref{fig:architecture_fft_decomposition}).

\begin{figure}
	\centering
	\includegraphics[scale=0.045]{img/architecture_fft_decomposition}
	\caption{Detailed architecture diagram of denoising network with frequency decomposition of input image}
	\label{fig:architecture_fft_decomposition}
\end{figure}

Implemented architecture (see Fig.~\ref{fig:architecture_fft_decomposition}) consists of a layer of frequency signal decomposition and sequential processing of parts of the input signal using convolutional blocks. Then the signals from blocks with are concatenated by channels and processed by a 3D convolutional layer to extract high-level features with interchannel dependence.

This architecture has $511390$ of trainable parameters and the weight of this model is $2$ megabytes when using single precision FP32 numbers to store the parameters.

\section{Training}


To use all frames from a series of images, one frame from a series was use to the network input, and a series averaging without an input frame was used as the expected output signal. Based on the sample \\$\{\tilde{I} _k\} _ {k=1}^{N}$, the input $X$ and the expected at the output of the network $y$ are constructed using the following formula:
\begin{equation}\label{eq:dataset}
X_i = \tilde{I_i},\ y = \frac{\sum_{k=1, k \ne i}^{N}\tilde{I_k}}{N - 1}
\end{equation}

Denoising model was trained on random cropped images and using the following augmentation: rotations by 90, 180, 270 degrees and flips.

For denoising models training was implemented pipeline based on PyTorch framework. As optimizer for was models training used radam optimizer (link to paper).

\section{Inference}
On inference input image unfolds on grid of crop. Network forwards on each crop with test-time data augmentation with transforms from training (link to paper). Result image computed by formula~(\ref{eq:times_series_augmentation}), where $T_{i}$ - augmentation transform, Ð° $T_{i}^{-1}$ - inverse transform.

\begin{eqnarray}\label{eq:times_series_augmentation}
I_{result}\ =\ \frac{\sum_{n=1}^{8} T_{i}^{-1}(T_{i}(f(x)))}{8}
\end{eqnarray}


\section{Results}
To test the quality of noise reduction, the PSNR (Peak Signal-to-Noise Ratio) metric is usually used. But this metric is incorrect for a datasets where there is no clean samples. For example, calculated the values of PSNR for quality estimation of output of the denoising mobile architecture (see Fig.~\ref{fig:real_noise_mobile} ) and of output of the architecture with frequency decomposition of input signal (see Fig.~\ref{fig:real_noise_advanced}). PSNR between output of the mobile architecture and average series value is $37.38$, and PSNR between output of the architecture with signal frequency decomposition and the average series value is $40.63$. The value of PSNR for mobile architecture is less than for architecture with frequency signal decomposition, but a visual comparison shows that it copes with the denoising problem worse. This is due to the fact that a noise component remains in the average value of the series.

For comparison, taken an unsupervised image denoising algorithm from the OpenCV library: Non-local means denoising. Additional examples of denoising networks results are shown (see Fig.~\ref{fig:real_noise_mobile_2}), (see Fig.~\ref{fig:real_noise_advanced_2}).

These models work only with frames received from the CMOS sensor from which the dataset was obtained for their training. An example of work on frames from another sensor is shown (see Fig.~\ref{fig:real_noise_webacam_advanced}). Visually seen the poor quality of the denoising result.

\begin{figure}
	\centering
	\includegraphics[scale=0.15]{img/real_noise_mobile}
	\caption{From left to right: original image, image obtained by averaging all frames in series, result of the mobile architecture, result of the non-local means denoising}
	\label{fig:real_noise_mobile}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.25]{img/real_noise_mobile_2}
	\caption{From left to right: original image, image obtained by averaging all frames in series, result of the mobile architecture, result of the non-local means denoising}
	\label{fig:real_noise_mobile_2}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[scale=0.15]{img/real_noise_advanced}
	\caption{From left to right: original image, image obtained by averaging all frames in series, result of the architecture with frequency decomposition of input signal, result of the non-local means denoising}
	\label{fig:real_noise_advanced}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.25]{img/real_noise_advanced_2}
	\caption{From left to right: original image, image obtained by averaging all frames in series, result of the architecture with frequency decomposition of input signal, result of the non-local means denoising}
	\label{fig:real_noise_advanced_2}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[scale=0.25]{img/real_noise_webacam_advanced}
	\caption{From left to right: original image, image obtained by averaging all frames in series, result of the mobile architecture, result of the non-local means denoising}
	\label{fig:real_noise_webacam_advanced}
\end{figure}

\section{Summary}
In the result implemented pipeline for training denoising models on datasets which has not contains clear images samples.
Have also been developed and tested architectures to effectively solve the noise reduction problem without clean data. 

According to visual estimation, trained denoising neural network architectures solve the set optimization problem~(\ref{eq:main_min_task}) quite effectively on the data collections collected for this work.


% \noindent Displayed equations are centered and set on a separate
% line.
% \begin{equation}
% x + y = z
% \end{equation}
% Please try to avoid rasterized images for line-art diagrams and
% schemas. Whenever possible, use vector graphics instead (see
% Fig.~\ref{fig1}).

% \begin{figure}
% \includegraphics[width=\textwidth]{fig1.eps}
% \caption{A figure caption is always placed below the illustration.
% Please note that short captions are centered, while long ones are
% justified by the macro package automatically.} \label{fig1}
% \end{figure}

%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\begin{thebibliography}{8}
\bibitem{ref_article1}
Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)

\bibitem{ref_lncs1}
Author, F., Author, S.: Title of a proceedings paper. In: Editor,
F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
Springer, Heidelberg (2016). \doi{10.10007/1234567890}

\bibitem{ref_book1}
Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
Location (1999)

\bibitem{ref_proc1}
Author, A.-B.: Contribution title. In: 9th International Proceedings
on Proceedings, pp. 1--2. Publisher, Location (2010)

\bibitem{ref_url1}
LNCS Homepage, \url{http://www.springer.com/lncs}. Last accessed 4
Oct 2017
\end{thebibliography}
\end{document}

